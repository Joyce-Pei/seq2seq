{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import gc\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcount_thres =1\n",
    "hidden_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of question-answer pairs: 109\n",
      "89 89\n",
      "encoder vocabulary_size: 210\n",
      "decoder vocabulary_size: 243\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = open('data/chatcorpus.txt', encoding='utf-8',\n",
    "             errors='ignore').read().split('\\n')\n",
    "\n",
    "#define split\n",
    "def mysplit(txt):\n",
    "    txt = clean_text(txt)\n",
    "    tokens = re.findall(r'\\w+|[^\\s\\w]+', txt)\n",
    "    return [t for t in tokens if t!=\"\"]\n",
    "    \n",
    "#remove abbreviations\n",
    "def clean_text(txt):\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(r\"i'm\", \"i am\", txt)\n",
    "    txt = re.sub(r\"he's\", \"he is\", txt)\n",
    "    txt = re.sub(r\"she's\", \"she is\", txt)\n",
    "    txt = re.sub(r\"that's\", \"that is\", txt)\n",
    "    txt = re.sub(r\"what's\", \"what is\", txt)\n",
    "    txt = re.sub(r\"where's\", \"where is\", txt)\n",
    "    txt = re.sub(r\"\\'ll\", \" will\", txt)\n",
    "    txt = re.sub(r\"\\'ve\", \" have\", txt)\n",
    "    txt = re.sub(r\"\\'re\", \" are\", txt)\n",
    "    txt = re.sub(r\"\\'d\", \" would\", txt)\n",
    "    txt = re.sub(r\"won't\", \"will not\", txt)\n",
    "    txt = re.sub(r\"can't\", \"can not\", txt)\n",
    "    txt = re.sub(r\"[^\\w\\s]\", \"\", txt)\n",
    "    return txt\n",
    "\n",
    "questions = []\n",
    "answers = []\n",
    "for line in lines:\n",
    "    line = line.split(\"\\t\")\n",
    "    ques = mysplit(line[0])\n",
    "    ans = mysplit(line[1])\n",
    "    questions.append(ques)\n",
    "    answers.append(ans)\n",
    "print(\"number of question-answer pairs:\",len(questions))\n",
    "\n",
    "ntrain_samples =  len(questions)-20 #use 20 samples for testing\n",
    "max_len = max([len(q) for q in questions])\n",
    "np.random.seed(0)\n",
    "inds = np.random.choice(len(questions),20,replace=False)\n",
    "test_questions = [questions[i] for i in inds]\n",
    "test_answers = [answers[i] for i in inds]\n",
    "questions=[questions[i] for i in range(len(questions)) if i not in inds]\n",
    "answers=[answers[i] for i in range(len(answers)) if i not in inds]\n",
    "print(len(questions),ntrain_samples)\n",
    "\n",
    "#encoder\n",
    "# get vocabulary\n",
    "wordcount = {}\n",
    "for line in questions:\n",
    "    for word in line:\n",
    "        wordcount[word] = wordcount.get(word,0)+1\n",
    "vocabulary = [w for w,c in wordcount.items() if c>=wordcount_thres]\n",
    "vocabulary = ['<EOS>', '<OUT>']+vocabulary #add tokens\n",
    "vocab={}\n",
    "i = len(vocab)\n",
    "for token in vocabulary:\n",
    "    vocab[token] = i\n",
    "    i += 1\n",
    "VOCAB_SIZE = len(vocab)\n",
    "print(\"encoder vocabulary_size:\",VOCAB_SIZE)  \n",
    "\n",
    "#decoding\n",
    "vocabulary=set()\n",
    "for line in answers:\n",
    "    vocabulary.update(line)\n",
    "vocabulary = list(vocabulary)\n",
    "vocabulary = ['<SOS>', '<EOS>']+vocabulary #add tokens\n",
    "dec_vocab={w:i for i,w in enumerate(vocabulary)}\n",
    "DEC_VOCAB_SIZE = len(vocabulary)\n",
    "print(\"decoder vocabulary_size:\",DEC_VOCAB_SIZE)  \n",
    "inv_vocab = {i:w for w,i in dec_vocab.items()}#for decoding\n",
    "\n",
    "\n",
    "def get_encoderinput(questions):\n",
    "    encoder_inp = []\n",
    "    for line in questions:\n",
    "        lst = []\n",
    "        for word in line:\n",
    "            if word not in vocab:\n",
    "                lst.append(vocab['<OUT>'])\n",
    "            else:\n",
    "                lst.append(vocab[word])\n",
    "        lst = torch.tensor(lst, dtype=torch.long, device=device).view(-1, 1)\n",
    "        encoder_inp.append(lst)\n",
    "    return encoder_inp\n",
    "encoder_inp = get_encoderinput(questions)\n",
    "\n",
    "def get_decoderinput(answers):\n",
    "    decoder_inp = []\n",
    "    for line in answers:\n",
    "        lst = [] #vocab[\"<SOS>\"]\n",
    "        for word in line:\n",
    "            lst.append(dec_vocab[word]) \n",
    "        lst.append(dec_vocab[\"<EOS>\"])\n",
    "        lst = torch.tensor(lst, dtype=torch.long, device=device).view(-1, 1)\n",
    "        decoder_inp.append(lst)\n",
    "    return decoder_inp\n",
    "decoder_inp = get_decoderinput(answers)\n",
    "\n",
    "# save memory space\n",
    "gc.collect()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['good', 'morning', 'how', 'are', 'you'],\n",
       " ['i', 'am', 'doing', 'well', 'how', 'about', 'you'],\n",
       " ['that', 'is', 'good', 'to', 'hear'],\n",
       " ['hello'],\n",
       " ['hi']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['i', 'am', 'doing', 'well', 'how', 'about', 'you'],\n",
       " ['i', 'am', 'also', 'good'],\n",
       " ['yes', 'it', 'is'],\n",
       " ['hi'],\n",
       " ['how', 'are', 'you', 'doing']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<EOS>': 0,\n",
       " '<OUT>': 1,\n",
       " 'good': 2,\n",
       " 'morning': 3,\n",
       " 'how': 4,\n",
       " 'are': 5,\n",
       " 'you': 6,\n",
       " 'i': 7,\n",
       " 'am': 8,\n",
       " 'doing': 9,\n",
       " 'well': 10,\n",
       " 'about': 11,\n",
       " 'that': 12,\n",
       " 'is': 13,\n",
       " 'to': 14,\n",
       " 'hear': 15,\n",
       " 'hello': 16,\n",
       " 'hi': 17,\n",
       " 'yes': 18,\n",
       " 'it': 19,\n",
       " 'have': 20,\n",
       " 'a': 21,\n",
       " 'question': 22,\n",
       " 'what': 23,\n",
       " 'your': 24,\n",
       " 'sorry': 25,\n",
       " 'but': 26,\n",
       " 'dont': 27,\n",
       " 'any': 28,\n",
       " 'thank': 29,\n",
       " 'anyway': 30,\n",
       " 'also': 31,\n",
       " 'heard': 32,\n",
       " 'the': 33,\n",
       " 'news': 34,\n",
       " 'favorite': 35,\n",
       " 'book': 36,\n",
       " 'can': 37,\n",
       " 'not': 38,\n",
       " 'read': 39,\n",
       " 'who': 40,\n",
       " 'then': 41,\n",
       " 'man': 42,\n",
       " 'in': 43,\n",
       " 'mask': 44,\n",
       " 'see': 45,\n",
       " 'its': 46,\n",
       " 'powers': 47,\n",
       " 'of': 48,\n",
       " 'observation': 49,\n",
       " 'doubt': 50,\n",
       " 'merely': 51,\n",
       " 'paradoxical': 52,\n",
       " 'nature': 53,\n",
       " 'asking': 54,\n",
       " 'masked': 55,\n",
       " 'tell': 56,\n",
       " 'me': 57,\n",
       " 'do': 58,\n",
       " 'like': 59,\n",
       " 'music': 60,\n",
       " 'seeing': 61,\n",
       " 'movies': 62,\n",
       " 'kind': 63,\n",
       " 'alice': 64,\n",
       " 'wonderland': 65,\n",
       " 'wish': 66,\n",
       " 'was': 67,\n",
       " 'mad': 68,\n",
       " 'hatter': 69,\n",
       " 'working': 70,\n",
       " 'on': 71,\n",
       " 'project': 72,\n",
       " 'cake': 73,\n",
       " 'lie': 74,\n",
       " 'no': 75,\n",
       " 'delicious': 76,\n",
       " 'else': 77,\n",
       " 'nothing': 78,\n",
       " 'or': 79,\n",
       " 'something': 80,\n",
       " 'self': 81,\n",
       " 'want': 82,\n",
       " 'know': 83,\n",
       " 'robot': 84,\n",
       " 'work': 85,\n",
       " 'complicated': 86,\n",
       " 'complex': 87,\n",
       " 'better': 88,\n",
       " 'than': 89,\n",
       " 'simple': 90,\n",
       " 'face': 91,\n",
       " 'ambiguity': 92,\n",
       " 'refuse': 93,\n",
       " 'temptation': 94,\n",
       " 'guess': 95,\n",
       " 'beautiful': 96,\n",
       " 'ugly': 97,\n",
       " 'explicit': 98,\n",
       " 'implicit': 99,\n",
       " 'flat': 100,\n",
       " 'nested': 101,\n",
       " 'readability': 102,\n",
       " 'counts': 103,\n",
       " 'special': 104,\n",
       " 'cases': 105,\n",
       " 'arent': 106,\n",
       " 'enough': 107,\n",
       " 'break': 108,\n",
       " 'rules': 109,\n",
       " 'although': 110,\n",
       " 'practicality': 111,\n",
       " 'beats': 112,\n",
       " 'purity': 113,\n",
       " 'errors': 114,\n",
       " 'should': 115,\n",
       " 'never': 116,\n",
       " 'pass': 117,\n",
       " 'silently': 118,\n",
       " 'unless': 119,\n",
       " 'explicitly': 120,\n",
       " 'silenced': 121,\n",
       " 'there': 122,\n",
       " 'be': 123,\n",
       " 'one': 124,\n",
       " 'and': 125,\n",
       " 'preferably': 126,\n",
       " 'only': 127,\n",
       " 'obvious': 128,\n",
       " 'way': 129,\n",
       " 'now': 130,\n",
       " 'often': 131,\n",
       " 'right': 132,\n",
       " 'if': 133,\n",
       " 'implementation': 134,\n",
       " 'hard': 135,\n",
       " 'explain': 136,\n",
       " 'bad': 137,\n",
       " 'idea': 138,\n",
       " 'easy': 139,\n",
       " 'may': 140,\n",
       " 'programmer': 141,\n",
       " 'use': 142,\n",
       " 'python': 143,\n",
       " 'java': 144,\n",
       " 'c': 145,\n",
       " 'quite': 146,\n",
       " 'bit': 147,\n",
       " 'myself': 148,\n",
       " 'annoys': 149,\n",
       " 'does': 150,\n",
       " 'yolo': 151,\n",
       " 'mean': 152,\n",
       " 'means': 153,\n",
       " 'live': 154,\n",
       " 'once': 155,\n",
       " 'where': 156,\n",
       " 'did': 157,\n",
       " 'ever': 158,\n",
       " 'depends': 159,\n",
       " 'define': 160,\n",
       " 'life': 161,\n",
       " 'ask': 162,\n",
       " 'hobbies': 163,\n",
       " 'playing': 164,\n",
       " 'soccer': 165,\n",
       " 'painting': 166,\n",
       " 'writing': 167,\n",
       " 'my': 168,\n",
       " 'love': 169,\n",
       " 'novels': 170,\n",
       " 'here': 171,\n",
       " 'for': 172,\n",
       " 'appointment': 173,\n",
       " 'with': 174,\n",
       " 'believe': 175,\n",
       " 'they': 176,\n",
       " 'said': 177,\n",
       " 'dr': 178,\n",
       " 'smith': 179,\n",
       " 'phone': 180,\n",
       " 'will': 181,\n",
       " 'mr': 182,\n",
       " 'davis': 183,\n",
       " 'feeling': 184,\n",
       " 'lost': 185,\n",
       " 'all': 186,\n",
       " 'money': 187,\n",
       " '20000': 188,\n",
       " 'so': 189,\n",
       " 'far': 190,\n",
       " 'today': 191,\n",
       " 'yesterday': 192,\n",
       " '13th': 193,\n",
       " 'correct': 194,\n",
       " 'mrs': 195,\n",
       " 'has': 196,\n",
       " 'husband': 197,\n",
       " 'been': 198,\n",
       " 'ms': 199,\n",
       " 'jacobs': 200,\n",
       " 'wondering': 201,\n",
       " 'could': 202,\n",
       " 'revise': 203,\n",
       " 'algorithm': 204,\n",
       " 'we': 205,\n",
       " 'discussed': 206,\n",
       " 'might': 207,\n",
       " 'able': 208,\n",
       " 'revisions': 209}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<SOS>': 0,\n",
       " '<EOS>': 1,\n",
       " 'and': 2,\n",
       " 'movies': 3,\n",
       " 'paradoxical': 4,\n",
       " 'good': 5,\n",
       " 'masked': 6,\n",
       " 'simple': 7,\n",
       " 'heard': 8,\n",
       " 'we': 9,\n",
       " 'news': 10,\n",
       " 'digits': 11,\n",
       " 'hard': 12,\n",
       " 'rules': 13,\n",
       " 'face': 14,\n",
       " 'borrow': 15,\n",
       " 'is': 16,\n",
       " 'practicality': 17,\n",
       " 'form': 18,\n",
       " 'better': 19,\n",
       " 'asking': 20,\n",
       " 'nothing': 21,\n",
       " 'with': 22,\n",
       " 'may': 23,\n",
       " 'if': 24,\n",
       " 'hardware': 25,\n",
       " 'its': 26,\n",
       " 'course': 27,\n",
       " 'office': 28,\n",
       " 'use': 29,\n",
       " 'no': 30,\n",
       " 'incredibly': 31,\n",
       " 'live': 32,\n",
       " 'one': 33,\n",
       " 'they': 34,\n",
       " 'his': 35,\n",
       " 'am': 36,\n",
       " 'should': 37,\n",
       " 'your': 38,\n",
       " 'cup': 39,\n",
       " 'he': 40,\n",
       " 'please': 41,\n",
       " 'idea': 42,\n",
       " 'including': 43,\n",
       " 'smith': 44,\n",
       " 'depends': 45,\n",
       " 'temptation': 46,\n",
       " 'those': 47,\n",
       " 'what': 48,\n",
       " 'or': 49,\n",
       " 'arent': 50,\n",
       " 'purity': 51,\n",
       " 'ask': 52,\n",
       " 'first': 53,\n",
       " 'seat': 54,\n",
       " 'doing': 55,\n",
       " 'color': 56,\n",
       " 'only': 57,\n",
       " 'been': 58,\n",
       " 'also': 59,\n",
       " 'man': 60,\n",
       " 'know': 61,\n",
       " 'how': 62,\n",
       " 'writing': 63,\n",
       " 'all': 64,\n",
       " 'implementation': 65,\n",
       " 'alice': 66,\n",
       " 'python': 67,\n",
       " '0': 68,\n",
       " 'work': 69,\n",
       " 'now': 70,\n",
       " 'other': 71,\n",
       " 'unless': 72,\n",
       " '500': 73,\n",
       " 'well': 74,\n",
       " 'more': 75,\n",
       " 'be': 76,\n",
       " 'flat': 77,\n",
       " 'love': 78,\n",
       " 'namespaces': 79,\n",
       " 'lot': 80,\n",
       " 'novels': 81,\n",
       " 'have': 82,\n",
       " 'able': 83,\n",
       " 'explicit': 84,\n",
       " 'secret': 85,\n",
       " 'lost': 86,\n",
       " 'so': 87,\n",
       " 'revisions': 88,\n",
       " 'following': 89,\n",
       " '1': 90,\n",
       " 'lets': 91,\n",
       " 'believe': 92,\n",
       " 'in': 93,\n",
       " 'define': 94,\n",
       " 'dr': 95,\n",
       " 'not': 96,\n",
       " 'fond': 97,\n",
       " 'phone': 98,\n",
       " 'entirely': 99,\n",
       " 'means': 100,\n",
       " 'but': 101,\n",
       " 'complicated': 102,\n",
       " 'hatter': 103,\n",
       " 'dutch': 104,\n",
       " 'somebody': 105,\n",
       " 'said': 106,\n",
       " '13th': 107,\n",
       " 'playing': 108,\n",
       " 'doubt': 109,\n",
       " 'wish': 110,\n",
       " 'ambiguity': 111,\n",
       " 'life': 112,\n",
       " 'read': 113,\n",
       " 'are': 114,\n",
       " 'that': 115,\n",
       " 'much': 116,\n",
       " 'things': 117,\n",
       " 'than': 118,\n",
       " 'soccer': 119,\n",
       " 'hobbies': 120,\n",
       " 'matter': 121,\n",
       " 'although': 122,\n",
       " 'familiar': 123,\n",
       " 'never': 124,\n",
       " 'enough': 125,\n",
       " 'money': 126,\n",
       " 'condition': 127,\n",
       " 'bit': 128,\n",
       " 'beats': 129,\n",
       " 'silenced': 130,\n",
       " 'obvious': 131,\n",
       " 'often': 132,\n",
       " 'exploring': 133,\n",
       " 'you': 134,\n",
       " 'way': 135,\n",
       " 'from': 136,\n",
       " 'has': 137,\n",
       " 'do': 138,\n",
       " 'about': 139,\n",
       " 'feeling': 140,\n",
       " 'seeing': 141,\n",
       " 'the': 142,\n",
       " 'refuse': 143,\n",
       " 'there': 144,\n",
       " 'people': 145,\n",
       " 'zen': 146,\n",
       " 'quite': 147,\n",
       " 'explicitly': 148,\n",
       " 'identify': 149,\n",
       " 'java': 150,\n",
       " 'easy': 151,\n",
       " 'might': 152,\n",
       " 'a': 153,\n",
       " 'errors': 154,\n",
       " 'it': 155,\n",
       " 'bad': 156,\n",
       " 'who': 157,\n",
       " 'implicit': 158,\n",
       " 'at': 159,\n",
       " 'cases': 160,\n",
       " 'my': 161,\n",
       " 'alright': 162,\n",
       " 'correct': 163,\n",
       " 'thank': 164,\n",
       " 'mad': 165,\n",
       " 'favorite': 166,\n",
       " 'nested': 167,\n",
       " 'on': 168,\n",
       " 'powers': 169,\n",
       " 'problem': 170,\n",
       " 'break': 171,\n",
       " 'appointment': 172,\n",
       " 'like': 173,\n",
       " 'did': 174,\n",
       " 'anything': 175,\n",
       " 'away': 176,\n",
       " 'seems': 177,\n",
       " 'sparse': 178,\n",
       " 'painting': 179,\n",
       " 'would': 180,\n",
       " 'function': 181,\n",
       " 'myself': 182,\n",
       " 'merely': 183,\n",
       " 'cake': 184,\n",
       " 'programmer': 185,\n",
       " 'once': 186,\n",
       " 'anyway': 187,\n",
       " 'best': 188,\n",
       " 'take': 189,\n",
       " 'see': 190,\n",
       " 'of': 191,\n",
       " 'hear': 192,\n",
       " 'was': 193,\n",
       " 'bird': 194,\n",
       " 'great': 195,\n",
       " 'to': 196,\n",
       " 'pass': 197,\n",
       " 'type': 198,\n",
       " 'sure': 199,\n",
       " 'yesterday': 200,\n",
       " 'can': 201,\n",
       " 'organisms': 202,\n",
       " 'where': 203,\n",
       " 'right': 204,\n",
       " 'wonderland': 205,\n",
       " 'delicious': 206,\n",
       " 'nature': 207,\n",
       " 'will': 208,\n",
       " 'yes': 209,\n",
       " 'self': 210,\n",
       " 'photo': 211,\n",
       " 'sugar': 212,\n",
       " 'this': 213,\n",
       " 'preferably': 214,\n",
       " 'guess': 215,\n",
       " 'robot': 216,\n",
       " 'dense': 217,\n",
       " 'hi': 218,\n",
       " 'working': 219,\n",
       " 'explain': 220,\n",
       " 'baking': 221,\n",
       " 'music': 222,\n",
       " 'silently': 223,\n",
       " 'help': 224,\n",
       " 'want': 225,\n",
       " 'inorganic': 226,\n",
       " 'could': 227,\n",
       " 'mask': 228,\n",
       " 'complex': 229,\n",
       " 'kind': 230,\n",
       " 'else': 231,\n",
       " 'special': 232,\n",
       " 'say': 233,\n",
       " 'honking': 234,\n",
       " 'distinguishes': 235,\n",
       " 'question': 236,\n",
       " 'i': 237,\n",
       " 'bonkers': 238,\n",
       " 'me': 239,\n",
       " 'tell': 240,\n",
       " 'something': 241,\n",
       " 'observation': 242}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89, 89)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoder_inp),len(decoder_inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ques_len = [len(q) for q in test_questions]\n",
    "ans_len = [len(a) for a in test_answers]\n",
    "\n",
    "plt.figure(figsize=(8,3))\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(ques_len,bins=10)\n",
    "plt.title(\"distribution of question length\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(ans_len,bins=10)\n",
    "plt.title(\"distribution of answer length\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        if rnn==\"RNN\":\n",
    "            self.rnn = nn.RNN(hidden_size, hidden_size, batch_first=True)\n",
    "        elif rnn==\"GRU\":\n",
    "            self.rnn = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        else:\n",
    "            self.rnn = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "\n",
    "    def forward(self, input, hidden, cell=None):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        if rnn in [\"RNN\",\"GRU\"]:\n",
    "            output, hidden = self.rnn(output, hidden)\n",
    "            return output, hidden\n",
    "        else:\n",
    "            output, (hidden, cell) = self.rnn(output, (hidden, cell))\n",
    "            return output, (hidden, cell) \n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "    \n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        if rnn==\"RNN\":\n",
    "            self.rnn = nn.RNN(hidden_size, hidden_size, batch_first=True)\n",
    "        elif rnn==\"GRU\":\n",
    "            self.rnn = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        else:\n",
    "            self.rnn = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden, cell=None):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        if rnn in [\"RNN\",\"GRU\"]:\n",
    "            output, hidden = self.rnn(output, hidden)\n",
    "            output = self.softmax(self.out(output[0]))\n",
    "            return output, hidden\n",
    "        else:\n",
    "            output, (hidden, cell) = self.rnn(output, (hidden, cell))\n",
    "            output = self.softmax(self.out(output[0]))\n",
    "            return output, (hidden, cell) \n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "    \n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=max_len):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.RNN(self.hidden_size, self.hidden_size, batch_first=True)\n",
    "        if rnn==\"RNN\":\n",
    "            self.rnn = nn.RNN(self.hidden_size, self.hidden_size, batch_first=True)\n",
    "        elif rnn==\"GRU\":\n",
    "            self.rnn = nn.GRU(self.hidden_size, self.hidden_size, batch_first=True)\n",
    "        else:\n",
    "            self.rnn = nn.LSTM(self.hidden_size, self.hidden_size, batch_first=True)\n",
    "            \n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs, cell=None):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "#         output, hidden = self.rnn(output, hidden)\n",
    "        if rnn in [\"RNN\",\"GRU\"]:\n",
    "            output, hidden = self.rnn(output, hidden)\n",
    "            output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "            return output, hidden, attn_weights\n",
    "        else:\n",
    "            output, (hidden, cell) = self.rnn(output, (hidden, cell))\n",
    "            output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "            return output, (hidden, cell), attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=max_len):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    if rnn in [\"RNN\",\"GRU\"]:\n",
    "        encoder_cell=None\n",
    "    else:\n",
    "        encoder_cell = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        if rnn in [\"RNN\",\"GRU\"]:\n",
    "            encoder_output, encoder_hidden = encoder(\n",
    "                input_tensor[ei], encoder_hidden)\n",
    "        else:\n",
    "            encoder_output, (encoder_hidden,encoder_cell) = encoder(\n",
    "                input_tensor[ei], encoder_hidden, cell=encoder_cell)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[dec_vocab[\"<SOS>\"]]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "    if rnn not in [\"RNN\",\"GRU\"]:\n",
    "        decoder_cell = encoder_cell\n",
    "\n",
    "    use_teacher_forcing = True if np.random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            if rnn in [\"RNN\",\"GRU\"]:\n",
    "                decoder_output, decoder_hidden = decoder(\n",
    "                    decoder_input, decoder_hidden)\n",
    "    #             decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "    #                 decoder_input, decoder_hidden, encoder_outputs)\n",
    "            else:\n",
    "                decoder_output, (decoder_hidden, decoder_cell) = decoder(\n",
    "                    decoder_input, decoder_hidden, cell=decoder_cell)\n",
    "    #             decoder_output, (decoder_hidden, decoder_cell), decoder_attention = decoder(\n",
    "    #                 decoder_input, decoder_hidden, encoder_outputs, cell=decoder_cell)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            if rnn in [\"RNN\",\"GRU\"]:\n",
    "                decoder_output, decoder_hidden = decoder(\n",
    "                    decoder_input, decoder_hidden)\n",
    "    #             decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "    #                 decoder_input, decoder_hidden, encoder_outputs)\n",
    "            else:\n",
    "                decoder_output, (decoder_hidden, decoder_cell) = decoder(\n",
    "                    decoder_input, decoder_hidden, cell=decoder_cell)\n",
    "    #             decoder_output, (decoder_hidden, decoder_cell), decoder_attention = decoder(\n",
    "    #                 decoder_input, decoder_hidden, encoder_outputs, cell=decoder_cell)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == dec_vocab[\"<EOS>\"]:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=max_len):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = get_encoderinput([sentence])[0]\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "        if rnn not in [\"RNN\",\"GRU\"]:\n",
    "            encoder_cell = encoder.initHidden()\n",
    "            \n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "#             encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "#                                                      encoder_hidden)\n",
    "            if rnn in [\"RNN\",\"GRU\"]:\n",
    "                encoder_output, encoder_hidden = encoder(\n",
    "                    input_tensor[ei], encoder_hidden)\n",
    "            else:\n",
    "                encoder_output, (encoder_hidden,encoder_cell) = encoder(\n",
    "                    input_tensor[ei], encoder_hidden, cell=encoder_cell)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[dec_vocab[\"<SOS>\"]]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "        if rnn not in [\"RNN\",\"GRU\"]:\n",
    "            decoder_cell = encoder_cell\n",
    "\n",
    "        decoded_words = []\n",
    "#         decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "#             decoder_output, decoder_hidden = decoder(\n",
    "#                 decoder_input, decoder_hidden)\n",
    "# #             decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "# #                 decoder_input, decoder_hidden, encoder_outputs)\n",
    "            if rnn in [\"RNN\",\"GRU\"]:\n",
    "                decoder_output, decoder_hidden = decoder(\n",
    "                    decoder_input, decoder_hidden)\n",
    "    #             decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "    #                 decoder_input, decoder_hidden, encoder_outputs)\n",
    "            else:\n",
    "                decoder_output, (decoder_hidden, decoder_cell) = decoder(\n",
    "                    decoder_input, decoder_hidden, cell=decoder_cell)\n",
    "    #             decoder_output, (decoder_hidden, decoder_cell), decoder_attention = decoder(\n",
    "    #                 decoder_input, decoder_hidden, encoder_outputs, cell=decoder_cell)\n",
    "    \n",
    "            #decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == dec_vocab[\"<EOS>\"]:\n",
    "                #decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(inv_vocab[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "        if len(decoded_words)==0:\n",
    "            return \"i am not sure\".split()\n",
    "        return decoded_words #, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate\n",
    "def calWordErrorRate1(ytruelist,ypredlist):\n",
    "    for y in ypredlist:\n",
    "        if y in ytruelist:\n",
    "            return 0\n",
    "    return 1 #error rate counting by word\n",
    "\n",
    "def calWordErrorRate(ytruelist,ypredlist):\n",
    "    error=0\n",
    "    for y in ypredlist:\n",
    "        if y not in ytruelist:\n",
    "            error+=1\n",
    "    return error/len(ypredlist) #error rate counting by word\n",
    "\n",
    "def computeWER(testset):\n",
    "    WER = []\n",
    "    WER_one = []\n",
    "    for i,sentence in enumerate(testset):\n",
    "        ytrue = testset[i]\n",
    "        decoded_translation = evaluate(encoder1, attn_decoder1, sentence)\n",
    "        e = calWordErrorRate(ytrue,decoded_translation)\n",
    "        WER.append(e)\n",
    "        WER_one.append(calWordErrorRate1(ytrue,decoded_translation))\n",
    "    wer = round(np.mean(WER),3)\n",
    "    wer1 = round(np.mean(WER_one),3)\n",
    "    print(\"WER:\",wer,\" WER counting one word:\",wer1)\n",
    "    return wer,wer1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "#     plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "    \n",
    "    #update method\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "                       \n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    minwer = 1.0\n",
    "    record = [None,None]\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        ind = np.random.choice(range(ntrain_samples))\n",
    "        input_tensor = encoder_inp[ind]\n",
    "        target_tensor = decoder_inp[ind]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "            print(\"train\", end=\" -- \")\n",
    "            wer, wer1 = computeWER(questions) #train\n",
    "            print(\"test\", end=\" -- \")\n",
    "            wer, wer1 = computeWER(test_questions)\n",
    "            if wer1<=minwer:\n",
    "                minwer=wer1\n",
    "                torch.save({'encoder': encoder.state_dict(), \n",
    "                            'decoder': decoder.state_dict()}, \n",
    "                           f\"checkpoint_file_{rnn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 2s (- 0m 47s) (300 5%) 3.0872\n",
      "train -- WER: 0.73  WER counting one word: 0.73\n",
      "test -- WER: 0.75  WER counting one word: 0.75\n",
      "0m 5s (- 0m 45s) (600 10%) 3.4029\n",
      "train -- WER: 0.738  WER counting one word: 0.472\n",
      "test -- WER: 0.75  WER counting one word: 0.5\n",
      "0m 7s (- 0m 43s) (900 15%) 3.2530\n",
      "train -- WER: 0.728  WER counting one word: 0.472\n",
      "test -- WER: 0.75  WER counting one word: 0.5\n",
      "0m 10s (- 0m 40s) (1200 20%) 3.1797\n",
      "train -- WER: 0.772  WER counting one word: 0.506\n",
      "test -- WER: 0.833  WER counting one word: 0.6\n",
      "0m 12s (- 0m 38s) (1500 25%) 3.1164\n",
      "train -- WER: 0.804  WER counting one word: 0.652\n",
      "test -- WER: 0.806  WER counting one word: 0.6\n",
      "0m 15s (- 0m 36s) (1800 30%) 2.7862\n",
      "train -- WER: 0.796  WER counting one word: 0.629\n",
      "test -- WER: 0.825  WER counting one word: 0.7\n",
      "0m 18s (- 0m 33s) (2100 35%) 2.5769\n",
      "train -- WER: 0.83  WER counting one word: 0.652\n",
      "test -- WER: 0.811  WER counting one word: 0.55\n",
      "0m 20s (- 0m 31s) (2400 40%) 2.3703\n",
      "train -- WER: 0.782  WER counting one word: 0.584\n",
      "test -- WER: 0.842  WER counting one word: 0.6\n",
      "0m 23s (- 0m 28s) (2700 45%) 2.0714\n",
      "train -- WER: 0.77  WER counting one word: 0.472\n",
      "test -- WER: 0.855  WER counting one word: 0.4\n",
      "0m 26s (- 0m 26s) (3000 50%) 1.7596\n",
      "train -- WER: 0.768  WER counting one word: 0.483\n",
      "test -- WER: 0.816  WER counting one word: 0.4\n",
      "0m 29s (- 0m 23s) (3300 55%) 1.4047\n",
      "train -- WER: 0.783  WER counting one word: 0.461\n",
      "test -- WER: 0.772  WER counting one word: 0.45\n",
      "0m 32s (- 0m 21s) (3600 60%) 1.0215\n",
      "train -- WER: 0.797  WER counting one word: 0.472\n",
      "test -- WER: 0.842  WER counting one word: 0.55\n",
      "0m 35s (- 0m 18s) (3900 65%) 0.7917\n",
      "train -- WER: 0.789  WER counting one word: 0.427\n",
      "test -- WER: 0.773  WER counting one word: 0.5\n",
      "0m 38s (- 0m 16s) (4200 70%) 0.6004\n",
      "train -- WER: 0.788  WER counting one word: 0.416\n",
      "test -- WER: 0.815  WER counting one word: 0.5\n",
      "0m 40s (- 0m 13s) (4500 75%) 0.5126\n",
      "train -- WER: 0.794  WER counting one word: 0.416\n",
      "test -- WER: 0.755  WER counting one word: 0.4\n",
      "0m 44s (- 0m 11s) (4800 80%) 0.4155\n",
      "train -- WER: 0.81  WER counting one word: 0.427\n",
      "test -- WER: 0.741  WER counting one word: 0.35\n",
      "0m 47s (- 0m 8s) (5100 85%) 0.3165\n",
      "train -- WER: 0.805  WER counting one word: 0.427\n",
      "test -- WER: 0.785  WER counting one word: 0.45\n",
      "0m 50s (- 0m 5s) (5400 90%) 0.2311\n",
      "train -- WER: 0.813  WER counting one word: 0.427\n",
      "test -- WER: 0.775  WER counting one word: 0.4\n",
      "0m 53s (- 0m 2s) (5700 95%) 0.2229\n",
      "train -- WER: 0.813  WER counting one word: 0.416\n",
      "test -- WER: 0.788  WER counting one word: 0.35\n",
      "0m 56s (- 0m 0s) (6000 100%) 0.1928\n",
      "train -- WER: 0.816  WER counting one word: 0.427\n",
      "test -- WER: 0.784  WER counting one word: 0.4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = \"LSTM\"\n",
    "encoder1 = EncoderRNN(VOCAB_SIZE, hidden_size).to(device)\n",
    "attn_decoder1 = DecoderRNN(hidden_size, DEC_VOCAB_SIZE).to(device)\n",
    "#use no atte\n",
    "trainIters(encoder1, attn_decoder1, 6000, print_every=300)\n",
    "\n",
    "checkpoint = torch.load(f\"checkpoint_file_{rnn}\")\n",
    "encoder1.load_state_dict(checkpoint['encoder'])\n",
    "attn_decoder1.load_state_dict(checkpoint['decoder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER: 0.788  WER counting one word: 0.35\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.788, 0.35)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "computeWER(test_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 2s (- 0m 41s) (300 5%) 3.2346\n",
      "train -- WER: 0.817  WER counting one word: 0.607\n",
      "test -- WER: 0.8  WER counting one word: 0.55\n",
      "0m 4s (- 0m 42s) (600 10%) 2.9924\n",
      "train -- WER: 0.846  WER counting one word: 0.652\n",
      "test -- WER: 0.885  WER counting one word: 0.65\n",
      "0m 7s (- 0m 42s) (900 15%) 2.4592\n",
      "train -- WER: 0.809  WER counting one word: 0.539\n",
      "test -- WER: 0.828  WER counting one word: 0.5\n",
      "0m 10s (- 0m 40s) (1200 20%) 1.8344\n",
      "train -- WER: 0.796  WER counting one word: 0.551\n",
      "test -- WER: 0.861  WER counting one word: 0.6\n",
      "0m 12s (- 0m 37s) (1500 25%) 1.4032\n",
      "train -- WER: 0.822  WER counting one word: 0.528\n",
      "test -- WER: 0.84  WER counting one word: 0.5\n",
      "0m 15s (- 0m 35s) (1800 30%) 1.0603\n",
      "train -- WER: 0.824  WER counting one word: 0.472\n",
      "test -- WER: 0.805  WER counting one word: 0.35\n",
      "0m 18s (- 0m 33s) (2100 35%) 0.7070\n",
      "train -- WER: 0.811  WER counting one word: 0.438\n",
      "test -- WER: 0.822  WER counting one word: 0.55\n",
      "0m 20s (- 0m 31s) (2400 40%) 0.5107\n",
      "train -- WER: 0.792  WER counting one word: 0.416\n",
      "test -- WER: 0.885  WER counting one word: 0.6\n",
      "0m 24s (- 0m 29s) (2700 45%) 0.4083\n",
      "train -- WER: 0.795  WER counting one word: 0.416\n",
      "test -- WER: 0.827  WER counting one word: 0.55\n",
      "0m 26s (- 0m 26s) (3000 50%) 0.2518\n",
      "train -- WER: 0.804  WER counting one word: 0.427\n",
      "test -- WER: 0.817  WER counting one word: 0.5\n",
      "0m 29s (- 0m 24s) (3300 55%) 0.2058\n",
      "train -- WER: 0.781  WER counting one word: 0.382\n",
      "test -- WER: 0.829  WER counting one word: 0.5\n",
      "0m 32s (- 0m 21s) (3600 60%) 0.1804\n",
      "train -- WER: 0.785  WER counting one word: 0.382\n",
      "test -- WER: 0.782  WER counting one word: 0.45\n",
      "0m 35s (- 0m 19s) (3900 65%) 0.1341\n",
      "train -- WER: 0.809  WER counting one word: 0.416\n",
      "test -- WER: 0.789  WER counting one word: 0.45\n",
      "0m 38s (- 0m 16s) (4200 70%) 0.1199\n",
      "train -- WER: 0.79  WER counting one word: 0.393\n",
      "test -- WER: 0.836  WER counting one word: 0.55\n",
      "0m 41s (- 0m 13s) (4500 75%) 0.0831\n",
      "train -- WER: 0.798  WER counting one word: 0.416\n",
      "test -- WER: 0.809  WER counting one word: 0.55\n",
      "0m 44s (- 0m 11s) (4800 80%) 0.0867\n",
      "train -- WER: 0.795  WER counting one word: 0.393\n",
      "test -- WER: 0.832  WER counting one word: 0.55\n",
      "0m 47s (- 0m 8s) (5100 85%) 0.0895\n",
      "train -- WER: 0.793  WER counting one word: 0.416\n",
      "test -- WER: 0.809  WER counting one word: 0.55\n",
      "0m 50s (- 0m 5s) (5400 90%) 0.0790\n",
      "train -- WER: 0.793  WER counting one word: 0.416\n",
      "test -- WER: 0.799  WER counting one word: 0.45\n",
      "0m 53s (- 0m 2s) (5700 95%) 0.0556\n",
      "train -- WER: 0.79  WER counting one word: 0.393\n",
      "test -- WER: 0.822  WER counting one word: 0.55\n",
      "0m 56s (- 0m 0s) (6000 100%) 0.0663\n",
      "train -- WER: 0.79  WER counting one word: 0.393\n",
      "test -- WER: 0.808  WER counting one word: 0.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = \"RNN\"\n",
    "encoder1 = EncoderRNN(VOCAB_SIZE, hidden_size).to(device)\n",
    "attn_decoder1 = DecoderRNN(hidden_size, DEC_VOCAB_SIZE).to(device)\n",
    "#use no atte\n",
    "trainIters(encoder1, attn_decoder1, 6000, print_every=300)\n",
    "\n",
    "checkpoint = torch.load(f\"checkpoint_file_{rnn}\")\n",
    "encoder1.load_state_dict(checkpoint['encoder'])\n",
    "attn_decoder1.load_state_dict(checkpoint['decoder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER: 0.805  WER counting one word: 0.35\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.805, 0.35)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "computeWER(test_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 2s (- 0m 38s) (300 5%) 3.1383\n",
      "train -- WER: 0.725  WER counting one word: 0.596\n",
      "test -- WER: 0.725  WER counting one word: 0.65\n",
      "0m 4s (- 0m 38s) (600 10%) 3.1673\n",
      "train -- WER: 0.777  WER counting one word: 0.674\n",
      "test -- WER: 0.8  WER counting one word: 0.75\n",
      "0m 6s (- 0m 38s) (900 15%) 3.0945\n",
      "train -- WER: 0.748  WER counting one word: 0.573\n",
      "test -- WER: 0.8  WER counting one word: 0.7\n",
      "0m 9s (- 0m 36s) (1200 20%) 2.7928\n",
      "train -- WER: 0.815  WER counting one word: 0.652\n",
      "test -- WER: 0.771  WER counting one word: 0.55\n",
      "0m 11s (- 0m 34s) (1500 25%) 2.6360\n",
      "train -- WER: 0.827  WER counting one word: 0.64\n",
      "test -- WER: 0.87  WER counting one word: 0.7\n",
      "0m 14s (- 0m 33s) (1800 30%) 2.4086\n",
      "train -- WER: 0.819  WER counting one word: 0.551\n",
      "test -- WER: 0.801  WER counting one word: 0.5\n",
      "0m 16s (- 0m 31s) (2100 35%) 2.0373\n",
      "train -- WER: 0.82  WER counting one word: 0.607\n",
      "test -- WER: 0.867  WER counting one word: 0.6\n",
      "0m 19s (- 0m 29s) (2400 40%) 1.8232\n",
      "train -- WER: 0.824  WER counting one word: 0.584\n",
      "test -- WER: 0.866  WER counting one word: 0.7\n",
      "0m 22s (- 0m 27s) (2700 45%) 1.3736\n",
      "train -- WER: 0.767  WER counting one word: 0.506\n",
      "test -- WER: 0.889  WER counting one word: 0.75\n",
      "0m 25s (- 0m 25s) (3000 50%) 1.1066\n",
      "train -- WER: 0.795  WER counting one word: 0.483\n",
      "test -- WER: 0.792  WER counting one word: 0.6\n",
      "0m 28s (- 0m 22s) (3300 55%) 0.9115\n",
      "train -- WER: 0.779  WER counting one word: 0.449\n",
      "test -- WER: 0.798  WER counting one word: 0.5\n",
      "0m 30s (- 0m 20s) (3600 60%) 0.6754\n",
      "train -- WER: 0.805  WER counting one word: 0.461\n",
      "test -- WER: 0.777  WER counting one word: 0.45\n",
      "0m 33s (- 0m 18s) (3900 65%) 0.4441\n",
      "train -- WER: 0.812  WER counting one word: 0.472\n",
      "test -- WER: 0.81  WER counting one word: 0.5\n",
      "0m 36s (- 0m 15s) (4200 70%) 0.4130\n",
      "train -- WER: 0.8  WER counting one word: 0.449\n",
      "test -- WER: 0.763  WER counting one word: 0.45\n",
      "0m 39s (- 0m 13s) (4500 75%) 0.3328\n",
      "train -- WER: 0.792  WER counting one word: 0.393\n",
      "test -- WER: 0.782  WER counting one word: 0.5\n",
      "0m 42s (- 0m 10s) (4800 80%) 0.2540\n",
      "train -- WER: 0.812  WER counting one word: 0.427\n",
      "test -- WER: 0.811  WER counting one word: 0.55\n",
      "0m 45s (- 0m 7s) (5100 85%) 0.2596\n",
      "train -- WER: 0.794  WER counting one word: 0.404\n",
      "test -- WER: 0.787  WER counting one word: 0.4\n",
      "0m 48s (- 0m 5s) (5400 90%) 0.2221\n",
      "train -- WER: 0.807  WER counting one word: 0.416\n",
      "test -- WER: 0.775  WER counting one word: 0.5\n",
      "0m 51s (- 0m 2s) (5700 95%) 0.1955\n",
      "train -- WER: 0.784  WER counting one word: 0.393\n",
      "test -- WER: 0.773  WER counting one word: 0.5\n",
      "0m 54s (- 0m 0s) (6000 100%) 0.1628\n",
      "train -- WER: 0.811  WER counting one word: 0.438\n",
      "test -- WER: 0.789  WER counting one word: 0.55\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = \"GRU\"\n",
    "encoder1 = EncoderRNN(VOCAB_SIZE, hidden_size).to(device)\n",
    "attn_decoder1 = DecoderRNN(hidden_size, DEC_VOCAB_SIZE).to(device)\n",
    "#use no atte\n",
    "trainIters(encoder1, attn_decoder1, 6000, print_every=300)\n",
    "\n",
    "checkpoint = torch.load(f\"checkpoint_file_{rnn}\")\n",
    "encoder1.load_state_dict(checkpoint['encoder'])\n",
    "attn_decoder1.load_state_dict(checkpoint['decoder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WER: 0.787  WER counting one word: 0.4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.787, 0.4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "computeWER(test_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question: life is the condition that distinguishes organisms from inorganic matter including\n",
      "true answer: e capacity for growth reproduction functional activity and continual change\n",
      "chatbot answer: i am not read\n",
      "\n",
      "question: can i help you with anything\n",
      "true answer: yes i have a question\n",
      "chatbot answer: i am not read\n",
      "\n",
      "question: of course i am a programmer\n",
      "true answer: i am indeed\n",
      "chatbot answer: of course i am a programmer\n",
      "\n",
      "question: i am also good\n",
      "true answer: that is good to hear\n",
      "chatbot answer: that is good\n",
      "\n",
      "question: who who is but a form following the function of what\n",
      "true answer: what are you then\n",
      "chatbot answer: i am but a man in a mask\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#show examples of output\n",
    "for i,sentence in enumerate(test_questions[:5]):\n",
    "    print(\"question:\",\" \".join(sentence))\n",
    "    print(\"true answer:\",\" \".join(test_answers[i]))\n",
    "    decoded_translation = evaluate(encoder1, attn_decoder1, sentence)\n",
    "    print(\"chatbot answer:\",\" \".join(decoded_translation))\n",
    "    print()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34mNEO:\n",
      "I am Neo. If you want to exit, type ciao\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from termcolor import colored\n",
    "\n",
    "#Response Fetching\n",
    "flag=False\n",
    "print(colored(\"NEO:\\nI am Neo. If you want to exit, type ciao\",'blue',attrs=['bold']))\n",
    "while(flag==True):\n",
    "    print(colored(\"\\nYOU:\",'red',attrs=['bold']))\n",
    "    u_input = input()\n",
    "    if(u_input!='ciao'):\n",
    "        print(colored(\"\\nNEO:\",'blue',attrs=['bold']))\n",
    "        sentence = mysplit(u_input)\n",
    "        decoded_translation = evaluate(encoder1, attn_decoder1, sentence)\n",
    "        decoded_sentence = \" \".join(decoded_translation)\n",
    "        print(colored(decoded_sentence.strip().capitalize(),'blue'))\n",
    "    else:\n",
    "        flag=False\n",
    "        print(colored(\"\\nNEO: Bye! take care..\",'blue', attrs=['bold']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
